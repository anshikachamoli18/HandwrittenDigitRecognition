Handwritten Digit Recognition with CNN and GUI
This project utilizes a Convolutional Neural Network (CNN) to recognize handwritten digits from the MNIST dataset with an impressive accuracy of 99.19%. The model architecture includes two convolutional layers (Conv2D), followed by max-pooling layers (MaxPool2D), flattening, dropout for regularization, and a final dense layer with softmax activation for classification. The model was trained on the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits.

Additionally, the project features a graphical user interface (GUI) built with Python, Pygame, and Keras, where users can draw digits on the screen. The GUI captures the user input, processes the drawn digit, and classifies it using the trained CNN model, displaying the predicted result in real-time. The interface also allows users to clear the screen and start a new drawing. This combination of deep learning and user-friendly interaction makes the project both functional and intuitive.
